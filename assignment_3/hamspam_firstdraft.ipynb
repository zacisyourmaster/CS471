{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS471: Introduction to Artificial Intelligence  \n",
    "## Assignment 3: Naive Bayes \n",
    "\n",
    "In this assignment, you will implement the Naive Bayes classification method\n",
    "For this assignment, you will be working with a Spam Collection dataset,\n",
    "consisting of text messages that have been collected for Spam research. \n",
    "\n",
    "The csv file contains one message per line with a total of 30 messages \n",
    "tagged either being ham (legitimate) or spam. Each line is composed of two columns: \n",
    "column 1 contains the label (ham or spam) and \n",
    "column 2 contains raw text.\n",
    "\n",
    "Consider the first 20 samples as your training set \n",
    "and the rest 10 samples for your testing. \n",
    "\n",
    "Tasks: \n",
    "Load the dataset and split into training and testing sets \n",
    "(first 20 into training and the rest into testing)  (1 point)\n",
    "\n",
    "\n",
    "Compute the prior probabilities: P(spam) and P(ham)  (2 points)\n",
    "\n",
    "\n",
    "Compute the conditional probabilities P(sentence/spam) (2 points)\n",
    "\n",
    "\n",
    "Compute the posterior probabilities \n",
    "(probability of a sentence belonging to a spam or ham) (2 points)\n",
    "P(spam/sentence) ∝ P(spam) * P(sentence/spam) \n",
    "Posterior ∝ prior * conditional\n",
    "P(ham/sentence) ∝ P(ham) * P(sentence/ham) \n",
    "\n",
    "\n",
    "For each sentence in the test set: (2 points)\n",
    "Display the sentence\n",
    "Print the posterior probability of a sentence belonging to spam or ham \n",
    "Display the class (spam or ham) \n",
    "\n",
    "\n",
    "Report the test set accuracy (1 point)\n",
    "Accuracy = no. of sentences correctly predicted by model / total sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=[]\n",
    "spam_data=[]\n",
    "ham_data=[]\n",
    "spam_words=[]\n",
    "ham_words=[]\n",
    "with open(r'SpamDetection.csv', 'r') as csv_file:\n",
    "    csv_reader = csv.reader(csv_file)\n",
    "    \n",
    "    next(csv_reader)\n",
    "    \n",
    "    for i,line in enumerate(csv_reader):\n",
    "        if i<20:\n",
    "            # training_data.append(line)\n",
    "            # spam_data.extend(line[1].split()) if line[0]=='spam' else ham_data.extend(line[1].split())\n",
    "            spam_data.append(line[1]) if line[0]=='spam' else ham_data.append(line[1])\n",
    "        else:\n",
    "            test_data.append(line)\n",
    "#Got Prior Probabilites of spam and ham\n",
    "p_spam=len(spam_data)/(len(spam_data)+len(ham_data))\n",
    "p_ham=len(ham_data)/(len(spam_data)+len(ham_data))\n",
    "\n",
    "for sentence in ham_data:\n",
    "    ham_words.extend([h for h in sentence.split()])\n",
    "for sentence in spam_data:\n",
    "    spam_words.extend([s for s in sentence.split()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = defaultdict(lambda: {'spam': 1, 'ham': 1})\n",
    "\n",
    "# Count spam words\n",
    "for word in spam_words:\n",
    "    word_dict[word]['spam'] += 1\n",
    "\n",
    "# Count ham words\n",
    "for word in ham_words:\n",
    "    word_dict[word]['ham'] += 1\n",
    "\n",
    "for word in word_dict:\n",
    "    word_dict[word]['spam']=(word_dict[word]['spam'])/(len(spam_words)+len(word_dict))\n",
    "    word_dict[word]['ham']=(word_dict[word]['ham'])/(len(ham_words)+len(word_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tell where you reached\n",
      "spam: 0.006617647058823529\n",
      "ham: 0.01284046692607004\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "Your gonna have to pick up a burger for yourself on your way home\n",
      "spam: 3.501902685098722e-20\n",
      "ham: 4.3181309045870886e-20\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "As a valued customer I am pleased to advise you that for your recent review you are awarded a Bonus Prize\n",
      "spam: 3.022520865276727e-32\n",
      "ham: 4.855590735349672e-32\n",
      "Predicted: ham\n",
      "Actual: spam\n",
      "Urgent you are awarded a complimentary trip to EuroDisinc To claim text immediately\n",
      "spam: 4.626513718827569e-15\n",
      "ham: 5.347654277195111e-16\n",
      "Predicted: Spam\n",
      "Actual: spam\n",
      "Finished class where are you\n",
      "spam: 3.8927335640138406e-05\n",
      "ham: 9.992581265424156e-05\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "where are you how did you perform \n",
      "spam: 4.9520832027450646e-12\n",
      "ham: 3.1788649561901397e-10\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "you can call me now\n",
      "spam: 8.913749764941117e-12\n",
      "ham: 2.3547147823630663e-11\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "I am waiting Call me once you are free\n",
      "spam: 5.140570798697299e-17\n",
      "ham: 4.278123421756089e-15\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "I am on the way to homei\n",
      "spam: 5.34824985896467e-12\n",
      "ham: 9.418859129452265e-11\n",
      "Predicted: ham\n",
      "Actual: ham\n",
      "Please call our customer service representative between 10am-9pm as you have WON a guaranteed cash prize\n",
      "spam: 4.082217987200797e-17\n",
      "ham: 2.0807993296479034e-18\n",
      "Predicted: Spam\n",
      "Actual: spam\n"
     ]
    }
   ],
   "source": [
    "test=\"Did you catch the train\"\n",
    "for test in test_data:\n",
    "    ham_score=p_ham\n",
    "    for word in test[1].split():\n",
    "        ham_score*=word_dict[word]['ham']\n",
    "        \n",
    "    spam_score=p_spam\n",
    "    for word in test[1].split():\n",
    "        spam_score*=word_dict[word]['spam']\n",
    "\n",
    "    print(test[1])\n",
    "    print(f'spam: {spam_score}')\n",
    "    print(f'ham: {ham_score}')\n",
    "    if(ham_score>spam_score):\n",
    "        print('Predicted: ham')\n",
    "    else:\n",
    "        print('Predicted: Spam')\n",
    "    print(f'Actual: {test[0]}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
